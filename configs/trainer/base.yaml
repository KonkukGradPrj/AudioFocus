# defaults
seed: ${seed}

# performance optimization
use_amp: True

################
# train
epochs: 10
clip_grad_norm: 0.5

loss: 'l2'
filter_every: false

optimizer_type: 'adamw'
optimizer:
  lr: 0.0001
  weight_decay: 0.00001
  betas: [0.9, 0.999]
  eps: 0.00000001

scheduler:
  first_cycle_steps: null
  cycle_mult: 1.0
  max_lr: ${trainer.optimizer.lr}
  min_lr: ${trainer.optimizer.lr}
  warmup_lr: 0.0
  warmup_ratio: 0.1
  gamma: 1.0


################ 
# evaluation
log_every: 100       # per_step
test_every: -1    # per_epoch

################ 
# knowledge distillation
temperature: 1